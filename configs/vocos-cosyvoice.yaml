# pytorch_lightning==1.8.6
seed_everything: 4444

data:
  class_path: vocos.dataset.VocosDataModule
  init_args:
    train_params:
      filelist_path: /home/zhou/data3/tts/vocos/dataset/train.txt
      sampling_rate: 16000
      num_samples: 16000
      batch_size: 32
      num_workers: 8

    val_params:
      filelist_path: /home/zhou/data3/tts/vocos/dataset/eval.txt
      sampling_rate: 16000
      num_samples: 48000
      batch_size: 15
      num_workers: 8

model:
  class_path: vocos.experiment.VocosCosyvoiceExp
  init_args:
    sample_rate: 16000
    initial_learning_rate: 1e-3
    mel_loss_coeff: 45
    mrd_loss_coeff: 1.0
    num_warmup_steps: 0 # Optimizers warmup steps
    pretrain_mel_steps: 0  # 0 means GAN objective from the first iteration

    # automatic evaluation
    evaluate_utmos: true
    evaluate_pesq: true
    evaluate_periodicty: true

    feature_extractor:
      class_path: vocos.feature_extractors.CosyvoiceFeatures
      init_args:
        onnx_model: /home/zhou/data3/tts/CosyVoice/pretrained_models/CosyVoice2-0.5B/speech_tokenizer_v2.onnx

    backbone:
      class_path: vocos.models.VocosBackbone
      init_args:
        input_channels: 768
        dim: 768
        intermediate_dim: 1152
        num_layers: 8
        adanorm_num_embeddings: 0  # len(bandwidths)

    head:
      class_path: vocos.heads.SnacHead
      init_args:
        input_channel: 768
        channels: 1024
        rates: [8, 5, 4, 4]
        noise: False
        depthwise: True
        attn_window_size: 5


trainer:
  logger:
    class_path: pytorch_lightning.loggers.TensorBoardLogger
    init_args:
      save_dir: logs/
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: val_loss
        filename: vocos_checkpoint_{epoch}_{step}_{val_loss:.4f}
        save_top_k: 3
        save_last: true
    - class_path: vocos.helpers.GradNormCallback

  # Lightning calculates max_steps across all optimizer steps (rather than number of batches)
  # This equals to 1M steps per generator and 1M per discriminator
  max_steps: 2000000
  # You might want to limit val batches when evaluating all the metrics, as they are time-consuming
  limit_val_batches: 30
  accelerator: gpu
  strategy: ddp
  devices: [ 0,1 ]
  log_every_n_steps: 100
