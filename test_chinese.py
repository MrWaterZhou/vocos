from transformers import AutoTokenizer, AutoModelForCausalLM
import sys
from snac import SNAC
import torch
import numpy as np
import torchaudio
from vocos import SnacVocos


def split_sequence(sequence):
    group_size = 7
    first_elements = []
    second_elements = []
    third_elements = []

    # Iterate over the sequence in chunks of 7
    for i in range(0, len(sequence), group_size):
        group = sequence[i:i + group_size]

        # Add elements to the respective lists based on their position in the group
        if len(group) >= 1:
            first_elements.append(group[0])
        if len(group) >= 5:
            second_elements.extend([group[1], group[4]])
        if len(group) >= 7:
            third_elements.extend([group[2], group[3], group[5], group[6]])
        else:
            third_elements.extend(group[2:])

    return first_elements, second_elements, third_elements


def sliding_window(data, window_size=7, step=7):
    return [data[i:i + window_size] for i in range(0, len(data) - window_size + 1, step)]


def test():
    tokenizer = AutoTokenizer.from_pretrained(sys.argv[1])
    model = AutoModelForCausalLM.from_pretrained(sys.argv[2], torch_dtype=torch.bfloat16).to('cuda')
    snac_model = SnacVocos.from_pretrained('/home/zhou/data3/tts/vocos/logs/lightning_logs/version_1').eval().to('cuda')

    def decode(l):
        first_elements, second_elements, third_elements = split_sequence(l)
        codes = [torch.from_numpy(np.array(x).astype(np.int32)[None,]).to('cuda') for x in
                 [first_elements, second_elements, third_elements]]
        audio_hat = snac_model.decode(codes)
        z_q = snac_model.quantizer.from_codes(codes)
        return audio_hat, z_q

    def prepare_input(text, prompt):
        text_ids = tokenizer(text, add_special_tokens=False).input_ids
        input_ids = prompt + [156000, 156010, 156005] + text_ids + [156006, 156007]
        input_ids = torch.tensor([input_ids], dtype=torch.int64).to('cuda')
        return input_ids

    with torch.no_grad():
        passages = ["买房真是越来越离谱了！", "房价涨得比工资快太多了，感觉不管怎么努力攒钱，永远追不上房价的步伐。",
                    "一线城市动辄几百万的房子，首付都够普通人奋斗半辈子了，更别说还贷三十年了。"]
        passages = [x.lower() for x in passages]
        prompts = [
            [156009, 155751, 155803, 155833, 155846, 155892, 155929, 155942, 155983, 156010, 156011],
            [156009, 155746, 155803, 155814, 155868, 155892, 155925, 155939, 155988, 156010, 156011],
            [156009, 155769, 155799, 155834, 155846, 155892, 155908, 155939, 155980, 156010, 156011],
            [156009, 155757, 155791, 155814, 155848, 155892, 155906, 155939, 155969, 156010, 156011],
            [156009, 155760, 155775, 155814, 155846, 155892, 155921, 155950, 155969, 156010, 156011],
            [156009, 155757, 155775, 155821, 155868, 155881, 155908, 155963, 155993, 156010, 156011],
            [156009, 155760, 155777, 155814, 155839, 155892, 155915, 155939, 155969, 156010, 156011],
            [156009, 155761, 155793, 155806, 155845, 155901, 155921, 155963, 155969, 156010, 156011],
            [156009, 155757, 155803, 155814, 155846, 155892, 155925, 155939, 155980, 156010, 156011],
            [156009, 155753, 155802, 155830, 155848, 155872, 155904, 155939, 155969, 156010, 156011],
            [156009, 155742, 155799, 155830, 155839, 155872, 155902, 155950, 155969, 156010, 156011],
            [156009, 155757, 155795, 155814, 155848, 155892, 155904, 155942, 155969, 156010, 156011],
            [156009, 155761, 155803, 155806, 155864, 155870, 155906, 155963, 155988, 156010, 156011],
            [156009, 155747, 155798, 155834, 155848, 155872, 155918, 155939, 155969, 156010, 156011],
            [156009, 155753, 155791, 155821, 155868, 155881, 155921, 155963, 155969, 156010, 156011],
            [156009, 155767, 155803, 155825, 155839, 155894, 155908, 155956, 155969, 156010, 156011],
            [156009, 155747, 155776, 155816, 155839, 155892, 155902, 155950, 155969, 156010, 156011],
            [156009, 155753, 155803, 155806, 155845, 155901, 155929, 155963, 155978, 156010, 156011],
            [156009, 155750, 155799, 155833, 155856, 155892, 155921, 155942, 155969, 156010, 156011],
            [156009, 155757, 155785, 155830, 155868, 155872, 155929, 155939, 155969, 156010, 156011],
            [156009, 155753, 155802, 155825, 155848, 155892, 155902, 155942, 155980, 156010, 156011],
            [156009, 155757, 155775, 155816, 155845, 155892, 155913, 155939, 155969, 156010, 156011],
            [156009, 155762, 155791, 155836, 155845, 155894, 155921, 155942, 155978, 156010, 156011],
            [156009, 155753, 155805, 155814, 155839, 155892, 155902, 155963, 155969, 156010, 156011],
            [156009, 155762, 155798, 155811, 155839, 155872, 155902, 155950, 155969, 156010, 156011],
            [156009, 155757, 155775, 155814, 155864, 155892, 155929, 155942, 155980, 156010, 156011],
            [156009, 155767, 155803, 155825, 155845, 155892, 155908, 155942, 155980, 156010, 156011],
            [156009, 155757, 155776, 155814, 155840, 155892, 155904, 155950, 155969, 156010, 156011],
            [156009, 155753, 155791, 155825, 155863, 155892, 155921, 155942, 155980, 156010, 156011],
            [156009, 155755, 155777, 155830, 155845, 155872, 155915, 155950, 155969, 156010, 156011],
            [156009, 155762, 155791, 155834, 155846, 155872, 155902, 155950, 155969, 156010, 156011],
            [156009, 155747, 155791, 155814, 155848, 155892, 155921, 155950, 155969, 156010, 156011],
            [156009, 155757, 155784, 155806, 155868, 155892, 155929, 155963, 155969, 156010, 156011],
            [156009, 155753, 155777, 155806, 155848, 155901, 155908, 155963, 155993, 156010, 156011],
            [156009, 155762, 155791, 155806, 155845, 155894, 155906, 155960, 155969, 156010, 156011],
            [156009, 155757, 155801, 155813, 155868, 155892, 155915, 155942, 155969, 156010, 156011],
            [156009, 155767, 155803, 155806, 155840, 155892, 155908, 155956, 155983, 156010, 156011],
            [156009, 155753, 155802, 155825, 155846, 155892, 155921, 155950, 155980, 156010, 156011],
            [156009, 155757, 155774, 155814, 155856, 155892, 155929, 155942, 155980, 156010, 156011],
            [156009, 155753, 155798, 155834, 155848, 155892, 155921, 155946, 155969, 156010, 156011],
            [156009, 155767, 155793, 155814, 155846, 155892, 155921, 155939, 155983, 156010, 156011],
            [156009, 155772, 155776, 155827, 155839, 155892, 155919, 155939, 155978, 156010, 156011],
            [156009, 155769, 155803, 155806, 155865, 155874, 155919, 155955, 155976, 156010, 156011],
            [156009, 155742, 155791, 155826, 155846, 155894, 155908, 155942, 155993, 156010, 156011],
            [156009, 155768, 155779, 155821, 155859, 155894, 155931, 155959, 155971, 156010, 156011],
            [156009, 155762, 155798, 155833, 155853, 155875, 155921, 155950, 155997, 156010, 156011],
            [156009, 155742, 155776, 155825, 155868, 155875, 155931, 155955, 155988, 156010, 156011],
            [156009, 155747, 155776, 155825, 155851, 155894, 155919, 155963, 155997, 156010, 156011],
            [156009, 155742, 155798, 155807, 155841, 155892, 155913, 155955, 155983, 156010, 156011],
            [156009, 155747, 155776, 155825, 155859, 155894, 155919, 155963, 155987, 156010, 156011],
            [156009, 155762, 155775, 155825, 155868, 155892, 155908, 155950, 155971, 156010, 156011],
            [156009, 155747, 155791, 155825, 155865, 155875, 155908, 155941, 155988, 156010, 156011],
            [156009, 155769, 155791, 155836, 155846, 155872, 155924, 155944, 155978, 156010, 156011]]
        for i, prompt in enumerate(prompts):
            try:
                z = []
                for x in passages:
                    if len(x) == 0:
                        break
                    x = prepare_input(x.strip(), prompt)
                    output_ids = model.generate(x, eos_token_id=156008, no_repeat_ngram_size=0, num_beams=1,
                                                do_sample=False, repetition_penalty=1.2,
                                                suppress_tokens=list(range(151641)))
                    output_ids = output_ids[0, x.shape[-1]:].cpu().numpy().tolist()
                    output_ids = [x for x in output_ids if x not in {156013, 156008}]
                    z = z + output_ids
                output_ids = [int(tokenizer.convert_ids_to_tokens(x).replace('<|speech-', '').replace('|>', '')) for x
                              in
                              z]
                with torch.no_grad():
                    audio_hat_all = snac_model.split_sequence(output_ids)
                    torchaudio.save('test_{}.wav'.format(i), audio_hat_all.cpu(), 24000)
            except Exception as e:
                print(e)


if __name__ == '__main__':
    test()
